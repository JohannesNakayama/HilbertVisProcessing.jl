library(readr)
readr::read_csv(file.path("..", "processed", "CDU.csv"))
files <- list.dirs("..", "processed")
files <- list.dirs(file.path("..", "processed"))
files <- list.dir(file.path("..", "processed"))
files <- list.files(file.path("..", "processed"))
files
readr::read_csv(file.path("..", "processed", "CDU.csv"))
readr::read_csv(file.path("..", "processed", files[3]))
readr::read_csv(file.path("..", "processed", files[7]))
a <- readr::read_csv(file.path("..", "processed", files[7]))
a
gsub(".csv", "", files[1])
for (f in files) {
tmp <- readr::read_csv(file.path("..", "processed", files[7]))
filename <- gsub(".csv", "", f)
print(f)
}
print(filename)
for (f in files) {
tmp <- readr::read_csv(file.path("..", "processed", files[7]))
filename <- gsub(".csv", "", f)
print(filename)
}
library(readr)
files <- list.files(file.path("..", "processed"))
for (f in files) {
tmp <- readr::read_csv(file.path("..", "processed", files[7]))
filename <- gsub(".csv", "", f)
print(filename)
}
"adlkj" + "qer"
library(readr)
files <- list.files(file.path("..", "processed"))
for (f in files) {
tmp <- readr::read_csv(file.path("..", "processed", files[7]))
filename <- gsub(".csv", "", f)
saveRDS(tmp, file = file.path("..", "processed", paste0(filename, ".rds")))
}
readRDS(file.path("..", "processed", "cdu.rds"))
a <- readRDS(file.path("..", "processed", "cdu.rds"))
a
library(dplyr)
a %>% select(language) %>% unique()
library(magrittr)
library(readr)
library(magrittr)
files <- list.files(file.path("..", "processed"))
source('C:/Users/naka9/Desktop/Arbeitsplatz/Digitale Muendigkeit/hilbert-vis/HilbertVisProcessing.jl/data_conversion/data_conversion.R', echo=TRUE)
library(readr)
library(magrittr)
files <- list.files(file.path("..", "processed"))
for (f in files) {
tmp <- readr::read_csv(file.path("..", "processed", files[7]))
filename <- gsub(".csv", "", f)
tmp %<>%
mutate(search_date = lubridate::as_date(search_date)) %>% # Fix date as only days
mutate(domain = str_replace_all(domain, "^[.](.+)", "\\1")) %>%  # fix some broken domains
mutate(url = str_replace_all(url, "^[.](.+)", "\\1")) %>%
mutate(url = str_remove(url, pattern = "&sa=.*$")) # remove left over google analytics url fragments
tmp %<>%
group_by(keyword, country, search_date, url, domain) %>%
filter(rank < 20) %>%
summarise(rank = sum(1/(rank + 1))) %>%
ungroup()
saveRDS(tmp, file = file.path("..", "processed", paste0(filename, ".rds")))
}
library(dplyr)
files <- list.files(file.path("..", "processed"))
for (f in files) {
tmp <- readr::read_csv(file.path("..", "processed", files[7]))
filename <- gsub(".csv", "", f)
tmp %<>%
mutate(search_date = lubridate::as_date(search_date)) %>% # Fix date as only days
mutate(domain = str_replace_all(domain, "^[.](.+)", "\\1")) %>%  # fix some broken domains
mutate(url = str_replace_all(url, "^[.](.+)", "\\1")) %>%
mutate(url = str_remove(url, pattern = "&sa=.*$")) # remove left over google analytics url fragments
tmp %<>%
group_by(keyword, country, search_date, url, domain) %>%
filter(rank < 20) %>%
summarise(rank = sum(1/(rank + 1))) %>%
ungroup()
saveRDS(tmp, file = file.path("..", "processed", paste0(filename, ".rds")))
}
library(stringr)
files <- list.files(file.path("..", "processed"))
for (f in files) {
tmp <- readr::read_csv(file.path("..", "processed", files[7]))
filename <- gsub(".csv", "", f)
tmp %<>%
mutate(search_date = lubridate::as_date(search_date)) %>% # Fix date as only days
mutate(domain = str_replace_all(domain, "^[.](.+)", "\\1")) %>%  # fix some broken domains
mutate(url = str_replace_all(url, "^[.](.+)", "\\1")) %>%
mutate(url = str_remove(url, pattern = "&sa=.*$")) # remove left over google analytics url fragments
tmp %<>%
group_by(keyword, country, search_date, url, domain) %>%
filter(rank < 20) %>%
summarise(rank = sum(1/(rank + 1))) %>%
ungroup()
saveRDS(tmp, file = file.path("..", "processed", paste0(filename, ".rds")))
}
tmp
tmp %<>%
mutate(search_date = lubridate::as_date(search_date)) %>% # Fix date as only days
# mutate(domain = str_replace_all(domain, "^[.](.+)", "\\1")) %>%  # fix some broken domains
mutate(url = str_replace_all(url, "^[.](.+)", "\\1")) %>%
mutate(url = str_remove(url, pattern = "&sa=.*$")) # remove left over google analytics url fragments
for (f in files) {
tmp <- readr::read_csv(file.path("..", "processed", files[7]))
filename <- gsub(".csv", "", f)
tmp %<>%
mutate(search_date = lubridate::as_date(search_date)) %>% # Fix date as only days
# mutate(domain = str_replace_all(domain, "^[.](.+)", "\\1")) %>%  # fix some broken domains
mutate(url = str_replace_all(url, "^[.](.+)", "\\1")) %>%
mutate(url = str_remove(url, pattern = "&sa=.*$")) # remove left over google analytics url fragments
tmp %<>%
group_by(keyword, country, search_date, url, domain) %>%
filter(rank < 20) %>%
summarise(rank = sum(1/(rank + 1))) %>%
ungroup()
saveRDS(tmp, file = file.path("..", "processed", paste0(filename, ".rds")))
}
tmp
tmp %<>%
mutate(search_date = lubridate::as_date(search_date)) %>% # Fix date as only days
# mutate(domain = str_replace_all(domain, "^[.](.+)", "\\1")) %>%  # fix some broken domains
mutate(url = str_replace_all(sourceUrl, "^[.](.+)", "\\1")) %>%
mutate(url = str_remove(url, pattern = "&sa=.*$")) # remove left over google analytics url fragments
library(stringr)
library(stringr)
files <- list.files(file.path("..", "processed"))
for (f in files) {
tmp <- readr::read_csv(file.path("..", "processed", files[7]))
filename <- gsub(".csv", "", f)
tmp %<>%
mutate(search_date = lubridate::as_date(search_date)) %>% # Fix date as only days
# mutate(domain = str_replace_all(domain, "^[.](.+)", "\\1")) %>%  # fix some broken domains
mutate(url = str_replace_all(sourceUrl, "^[.](.+)", "\\1")) %>%
mutate(url = str_remove(url, pattern = "&sa=.*$")) # remove left over google analytics url fragments
tmp %<>%
group_by(keyword, country, search_date, url, domain) %>%
filter(rank < 20) %>%
summarise(rank = sum(1/(rank + 1))) %>%
ungroup()
saveRDS(tmp, file = file.path("..", "processed", paste0(filename, ".rds")))
}
tmp
files <- list.files(file.path("..", "processed"))
for (f in files) {
tmp <- readr::read_csv(file.path("..", "processed", f))
filename <- gsub(".csv", "", f)
tmp %<>%
mutate(search_date = lubridate::as_date(search_date)) %>% # Fix date as only days
# mutate(domain = str_replace_all(domain, "^[.](.+)", "\\1")) %>%  # fix some broken domains
mutate(url = str_replace_all(sourceUrl, "^[.](.+)", "\\1")) %>%
mutate(url = str_remove(url, pattern = "&sa=.*$")) # remove left over google analytics url fragments
tmp %<>%
filter(rank <= 20) %>%
group_by(keyword, search_date, url, domain) %>%
summarise(rank = sum(1/(rank + 1))) %>%
ungroup()
saveRDS(tmp, file = file.path("..", "processed", paste0(filename, ".rds")))
}
library(stringr)
files <- list.files(file.path("..", "processed"))
for (f in files) {
tmp <- readr::read_csv(file.path("..", "processed", f))
filename <- gsub(".csv", "", f)
tmp %<>%
mutate(search_date = lubridate::as_date(search_date)) %>% # Fix date as only days
# mutate(domain = str_replace_all(domain, "^[.](.+)", "\\1")) %>%  # fix some broken domains
mutate(url = str_replace_all(sourceUrl, "^[.](.+)", "\\1")) %>%
mutate(url = str_remove(url, pattern = "&sa=.*$")) # remove left over google analytics url fragments
tmp %<>%
filter(rank <= 20) %>%
group_by(keyword, search_date, url) %>%
summarise(rank = sum(1/(rank + 1))) %>%
ungroup()
saveRDS(tmp, file = file.path("..", "processed", paste0(filename, ".rds")))
}
library(readr)
library(magrittr)
library(dplyr)
library(stringr)
files <- list.files(file.path("..", "processed"))
for (f in files) {
tmp <- readr::read_csv(file.path("..", "processed", f))
filename <- gsub(".csv", "", f)
tmp %<>%
mutate(search_date = lubridate::as_date(search_date)) %>% # Fix date as only days
# mutate(domain = str_replace_all(domain, "^[.](.+)", "\\1")) %>%  # fix some broken domains
mutate(url = str_replace_all(sourceUrl, "^[.](.+)", "\\1")) %>%
mutate(url = str_remove(url, pattern = "&sa=.*$")) # remove left over google analytics url fragments
tmp %<>%
filter(rank <= 20) %>%
group_by(keyword, search_date, url) %>%
summarise(rank = sum(1/(rank + 1))) %>%
ungroup()
saveRDS(tmp, file = file.path("..", "processed", paste0(filename, ".rds")))
}
